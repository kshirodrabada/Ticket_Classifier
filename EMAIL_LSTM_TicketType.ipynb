{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import nltk\n",
    "import pickle\n",
    "from nltk.corpus import stopwords\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Embedding, LSTM, GlobalMaxPooling1D, SpatialDropout1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "emails=pd.read_csv(\"endava_email_tickets_ML.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "regexList = []\n",
    "regexList += ['From:(.*)\\r\\n']  # from line\n",
    "regexList += ['^[_a-z0-9-]+(\\.[_a-z0-9-]+)*@[a-z0-9-]+(\\.[a-z0-9-]+)*(\\.[a-z]{2,4})$']\n",
    "regexList += ['[\\w\\d\\-\\_\\.]+ @ [\\w\\d\\-\\_\\.]+']\n",
    "regexList += ['Subject:']\n",
    "regexList += ['[^a-zA-Z]']\n",
    "emails['body'] = emails['body'].replace(regexList, ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_list = {r\"i'm\": 'i am',\n",
    "                r\"'re\": ' are',\n",
    "                r\"let’s\": 'let us',\n",
    "                r\"'s\":  ' is',\n",
    "                r\"'ve\": ' have',\n",
    "                r\"can't\": 'can not',\n",
    "                r\"cannot\": 'can not',\n",
    "                r\"shan’t\": 'shall not',\n",
    "                r\"n't\": ' not',\n",
    "                r\"'d\": ' would',\n",
    "                r\"'ll\": ' will',\n",
    "                r\"'scuse\": 'excuse',\n",
    "                ',': ' ,',\n",
    "                '.': ' .',\n",
    "                '!': ' !',\n",
    "                '?': ' ?',\n",
    "                '\\s+': ' '}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower()    \n",
    "    for s in replace_list:\n",
    "        text = text.replace(s, replace_list[s])\n",
    "    text = ' '.join(text.split())\n",
    "    return text\n",
    "X_body = emails['body'].apply(lambda p: clean_text(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_ticket_type = emails['ticket_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase_len = X_body.apply(lambda p: len(p.split(' ')))\n",
    "max_phrase_len = phrase_len.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 5000\n",
    "tokenizer = Tokenizer(num_words = max_words)\n",
    "tokenizer.fit_on_texts(X_body)\n",
    "X = tokenizer.texts_to_sequences(X_body)\n",
    "X = pad_sequences(X, maxlen = max_phrase_len)\n",
    "Y = to_categorical(Y_ticket_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "980"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_phrase_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,Y, test_size = 0.30, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1211 20:28:35.278507  7872 deprecation_wrapper.py:119] From C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W1211 20:28:35.729145  7872 deprecation_wrapper.py:119] From C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W1211 20:28:35.734623  7872 deprecation_wrapper.py:119] From C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W1211 20:28:35.824780  7872 deprecation_wrapper.py:119] From C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W1211 20:28:35.852732  7872 deprecation.py:506] From C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W1211 20:28:38.100692  7872 deprecation_wrapper.py:119] From C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W1211 20:28:38.230387  7872 deprecation_wrapper.py:119] From C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_lstm_ttype = Sequential()\n",
    "model_lstm_ttype.add(Embedding(10000, 128, input_length = max_phrase_len))\n",
    "model_lstm_ttype.add(SpatialDropout1D(0.3))\n",
    "model_lstm_ttype.add(LSTM(128, dropout = 0.3, recurrent_dropout = 0.3))\n",
    "model_lstm_ttype.add(Dense(2, activation = 'softmax'))\n",
    "model_lstm_ttype.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='Adam',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1211 20:29:00.916250  7872 deprecation.py:323] From C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 23788 samples, validate on 10196 samples\n",
      "Epoch 1/1\n",
      "23788/23788 [==============================] - 3905s 164ms/step - loss: 0.1244 - acc: 0.9470 - val_loss: 0.0174 - val_acc: 0.9948\n"
     ]
    }
   ],
   "source": [
    "history = model_lstm_ttype.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    validation_split = 0.3,\n",
    "    epochs = 1,\n",
    "    batch_size = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14565/14565 [==============================] - 991s 68ms/step\n"
     ]
    }
   ],
   "source": [
    "accr_ttype = model_lstm_ttype.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0171144532336215, 0.9939581187778922]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accr_ttype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(model_lstm_ttype, open('model_ttype.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=['icon dear please setup icon per icon engineers please let other details needed thanks lead']\n",
    "test_tokens = tokenizer.texts_to_sequences(test)\n",
    "test_sequence = pad_sequences(test_tokens, maxlen = max_phrase_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "model = pickle.load(open('model_ttype.pkl','rb'))\n",
    "print(np.argmax(model.predict(test_sequence)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
